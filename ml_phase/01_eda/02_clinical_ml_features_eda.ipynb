{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1.2: Clinical ML Features - Exploratory Data Analysis\n",
    "**DNA Gene Mapping Project - ML Phase**  \n",
    "**Author:** Sharique Mohammad  \n",
    "**Date:** February 2026  \n",
    "\n",
    "## Objective\n",
    "Analyze clinical pathogenicity features, variant classification, review quality, and conservation scores.\n",
    "\n",
    "## Data Source\n",
    "- Table: `clinical_ml_features`\n",
    "- Rows: ~4.1M variants (10% sample for EDA)\n",
    "- Focus: Clinical significance, review status, conservation scores\n",
    "\n",
    "## Deliverables\n",
    "- 15+ visualizations\n",
    "- Clinical EDA report (txt)\n",
    "- Missing value analysis (csv)\n",
    "- Correlation matrix (csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path().absolute().parent.parent\n",
    "FIGURES_DIR = PROJECT_ROOT / 'data' / 'analytical' / 'figures' / 'clinical_eda'\n",
    "REPORTS_DIR = PROJECT_ROOT / 'data' / 'analytical' / 'reports'\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete\")\n",
    "print(f\"Figures: {FIGURES_DIR}\")\n",
    "print(f\"Reports: {REPORTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection\n",
    "load_dotenv()\n",
    "\n",
    "POSTGRES_HOST = os.getenv('POSTGRES_HOST', 'localhost')\n",
    "POSTGRES_PORT = os.getenv('POSTGRES_PORT', '5432')\n",
    "POSTGRES_DB = os.getenv('POSTGRES_DB', 'genome_db')\n",
    "POSTGRES_USER = os.getenv('POSTGRES_USER', 'postgres')\n",
    "POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "\n",
    "conn_str = f\"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\"\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "print(\"Database connection established\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clinical_ml_features (10% sample)\n",
    "print(\"Loading clinical_ml_features (10% sample)...\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT * FROM gold.clinical_ml_features \n",
    "TABLESAMPLE SYSTEM (10)\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "print(f\" Loaded: {len(df):,} rows, {len(df.columns)} columns\")\n",
    "print(f\"  Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clinical significance distribution\n",
    "print(\"Clinical Significance Distribution:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# CRITICAL: Convert target columns to boolean FIRST\n",
    "target_cols = ['target_is_pathogenic', 'target_is_benign', 'target_is_vus']\n",
    "\n",
    "for col in target_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('false').astype(str).str.lower().str.strip()\n",
    "        df[col] = df[col].map({\n",
    "            'true': True, 't': True, '1': True, 'yes': True,\n",
    "            'false': False, 'f': False, '0': False, 'no': False, '': False\n",
    "        }).fillna(False)\n",
    "\n",
    "# NOW do the sum (on actual booleans)\n",
    "pathogenic_count = int(df['target_is_pathogenic'].sum()) if 'target_is_pathogenic' in df.columns else 0\n",
    "benign_count = int(df['target_is_benign'].sum()) if 'target_is_benign' in df.columns else 0\n",
    "vus_count = int(df['target_is_vus'].sum()) if 'target_is_vus' in df.columns else 0\n",
    "\n",
    "total = len(df)\n",
    "\n",
    "sig_data = pd.DataFrame({\n",
    "    'Category': ['Pathogenic', 'Benign', 'VUS'],\n",
    "    'Count': [pathogenic_count, benign_count, vus_count],\n",
    "    'Percentage': [\n",
    "        pathogenic_count/total*100,\n",
    "        benign_count/total*100,\n",
    "        vus_count/total*100\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(sig_data.to_string(index=False))\n",
    "\n",
    "if pathogenic_count > 0 and benign_count > 0:\n",
    "    ratio = max(pathogenic_count, benign_count) / min(pathogenic_count, benign_count)\n",
    "    print(f\"\\nClass imbalance ratio: {ratio:.2f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL: Convert TEXT columns to proper types\n",
    "print(\"Converting TEXT columns to proper data types...\")\n",
    "\n",
    "# Numeric columns stored as TEXT in PostgreSQL\n",
    "numeric_cols = [\n",
    "    'review_quality_score', 'number_submitters', 'review_confidence_score',\n",
    "    'pathogenicity_score', 'conservation_score', 'combined_pathogenicity_risk',\n",
    "    'phylop_score', 'cadd_score', 'gerp_score', 'phastcons_score',\n",
    "    'gene_conservation_score', 'allele_frequency', 'gnomad_af', 'cadd_phred'\n",
    "]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Boolean columns - handle multiple possible formats\n",
    "boolean_cols = [col for col in df.columns if col.startswith('is_') or col.startswith('has_')]\n",
    "\n",
    "for col in boolean_cols:\n",
    "    if col in df.columns:\n",
    "        # Convert to string first, handle nulls\n",
    "        df[col] = df[col].fillna('false').astype(str).str.lower().str.strip()\n",
    "        # Map various boolean representations\n",
    "        df[col] = df[col].map({\n",
    "            'true': True, 't': True, '1': True, 'yes': True,\n",
    "            'false': False, 'f': False, '0': False, 'no': False, '': False\n",
    "        }).fillna(False)\n",
    "\n",
    "print(f\"Converted {len([c for c in numeric_cols if c in df.columns])} numeric columns\")\n",
    "print(f\"Converted {len(boolean_cols)} boolean columns\")\n",
    "\n",
    "# Verify conversions\n",
    "print(\"\\nVerification:\")\n",
    "print(f\"  is_pathogenic TRUE count: {df['is_pathogenic'].sum() if 'is_pathogenic' in df.columns else 'N/A'}\")\n",
    "print(f\"  is_benign TRUE count: {df['is_benign'].sum() if 'is_benign' in df.columns else 'N/A'}\")\n",
    "print(f\"  is_vus TRUE count: {df['is_vus'].sum() if 'is_vus' in df.columns else 'N/A'}\")\n",
    "\n",
    "print(\"\\nData types after conversion:\")\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSTIC: Verify conversion actually worked\n",
    "print(\"POST-CONVERSION DIAGNOSTIC:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check target columns specifically\n",
    "target_cols = ['target_is_pathogenic', 'target_is_benign', 'target_is_vus']\n",
    "for col in target_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Dtype: {df[col].dtype}\")\n",
    "        print(f\"  Unique values: {df[col].unique()}\")\n",
    "        print(f\"  Value counts:\\n{df[col].value_counts()}\")\n",
    "        print(f\"  TRUE count: {df[col].sum()}\")\n",
    "\n",
    "# Check review_status\n",
    "if 'review_status' in df.columns:\n",
    "    print(f\"\\nreview_status:\")\n",
    "    print(f\"  Dtype: {df[col].dtype}\")\n",
    "    print(f\"  Value counts:\\n{df['review_status'].value_counts()}\")\n",
    "\n",
    "# Check conservation scores\n",
    "conservation_cols = ['phylop_score', 'cadd_score', 'gerp_score', 'phastcons_score']\n",
    "for col in conservation_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Dtype: {df[col].dtype}\")\n",
    "        print(f\"  Non-null count: {df[col].notna().sum()}\")\n",
    "        print(f\"  Mean: {df[col].mean():.3f}\" if df[col].notna().any() else \"  All NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first rows\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value analysis\n",
    "missing = pd.DataFrame({\n",
    "    'column': df.columns,\n",
    "    'missing_count': df.isnull().sum(),\n",
    "    'missing_pct': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "}).sort_values('missing_pct', ascending=False)\n",
    "\n",
    "print(\"Missing Values Summary (Top 20):\")\n",
    "print(missing.head(20).to_string(index=False))\n",
    "\n",
    "# Save\n",
    "missing.to_csv(REPORTS_DIR / 'clinical_missing_values.csv', index=False)\n",
    "print(f\"\\nSaved: {REPORTS_DIR / 'clinical_missing_values.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clinical Significance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clinical significance distribution\n",
    "print(\"Clinical Significance Distribution:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Count each category (already converted to boolean)\n",
    "pathogenic_count = df['is_pathogenic'].sum() if 'is_pathogenic' in df.columns else 0\n",
    "likely_pathogenic_count = df['is_likely_pathogenic'].sum() if 'is_likely_pathogenic' in df.columns else 0\n",
    "vus_count = df['is_vus'].sum() if 'is_vus' in df.columns else 0\n",
    "likely_benign_count = df['is_likely_benign'].sum() if 'is_likely_benign' in df.columns else 0\n",
    "benign_count = df['is_benign'].sum() if 'is_benign' in df.columns else 0\n",
    "\n",
    "total = len(df)\n",
    "\n",
    "sig_data = pd.DataFrame({\n",
    "    'Category': ['Pathogenic', 'Likely Pathogenic', 'VUS', 'Likely Benign', 'Benign'],\n",
    "    'Count': [pathogenic_count, likely_pathogenic_count, vus_count, likely_benign_count, benign_count],\n",
    "    'Percentage': [\n",
    "        pathogenic_count/total*100,\n",
    "        likely_pathogenic_count/total*100,\n",
    "        vus_count/total*100,\n",
    "        likely_benign_count/total*100,\n",
    "        benign_count/total*100\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(sig_data.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: 3-class significance distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = ['#e74c3c', '#27ae60', '#95a5a6']\n",
    "bars = ax.bar(sig_data['Category'], sig_data['Count'], color=colors, alpha=0.8, edgecolor='black')\n",
    "\n",
    "# Add labels\n",
    "for bar, pct in zip(bars, sig_data['Percentage']):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{pct:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Variant Count', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Clinical Significance Distribution (3 Classes)', fontsize=14, fontweight='bold')\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}'))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(FIGURES_DIR / '01_clinical_significance_3class.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved: {FIGURES_DIR / '01_clinical_significance_3class.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification: Pathogenic vs Benign (excluding VUS)\n",
    "binary_pathogenic = pathogenic_count\n",
    "binary_benign = benign_count\n",
    "binary_total = binary_pathogenic + binary_benign\n",
    "\n",
    "if binary_total > 0:\n",
    "    print(f\"\\nBinary Classification (Pathogenic vs Benign):\")\n",
    "    print(f\"  Pathogenic: {binary_pathogenic:,} ({binary_pathogenic/binary_total*100:.1f}%)\")\n",
    "    print(f\"  Benign:     {binary_benign:,} ({binary_benign/binary_total*100:.1f}%)\")\n",
    "    \n",
    "    if binary_pathogenic > 0 and binary_benign > 0:\n",
    "        ratio = max(binary_pathogenic, binary_benign) / min(binary_pathogenic, binary_benign)\n",
    "        print(f\"  Class imbalance: {ratio:.2f}:1\")\n",
    "    \n",
    "    # Pie chart\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    wedges, texts, autotexts = ax.pie(\n",
    "        [binary_pathogenic, binary_benign],\n",
    "        labels=['Pathogenic', 'Benign'],\n",
    "        autopct='%1.1f%%',\n",
    "        colors=['#e74c3c', '#27ae60'],\n",
    "        startangle=90,\n",
    "        textprops={'fontsize': 12, 'fontweight': 'bold'}\n",
    "    )\n",
    "    \n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "    \n",
    "    ax.set_title('Binary Classification: Pathogenic vs Benign', fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(FIGURES_DIR / '02_binary_classification.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved: {FIGURES_DIR / '02_binary_classification.png'}\")\n",
    "else:\n",
    "    print(\"\\nNo pathogenic/benign variants for binary classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Review Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review status distribution\n",
    "if 'review_status' in df.columns:\n",
    "    print(\"Review Status Distribution:\")\n",
    "    review_dist = df['review_status'].value_counts()\n",
    "    review_pct = df['review_status'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    review_df = pd.DataFrame({\n",
    "        'Review Status': review_dist.index,\n",
    "        'Count': review_dist.values,\n",
    "        'Percentage': review_pct.values.round(2)\n",
    "    })\n",
    "    \n",
    "    print(review_df.to_string(index=False))\n",
    "    \n",
    "    # Bar chart\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    bars = ax.barh(review_df['Review Status'], review_df['Count'], color='steelblue', alpha=0.7)\n",
    "    \n",
    "    for bar, count in zip(bars, review_df['Count']):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "                f'{int(count):,}',\n",
    "                ha='left', va='center', fontsize=10)\n",
    "    \n",
    "    ax.set_xlabel('Variant Count', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Review Status Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(FIGURES_DIR / '03_review_status.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved: {FIGURES_DIR / '03_review_status.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review quality score distribution (0-4 scale)\n",
    "if 'review_quality_score' in df.columns:\n",
    "    print(\"\\nReview Quality Score Distribution (0-4 scale):\")\n",
    "    \n",
    "    quality_scores = df['review_quality_score'].dropna()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Histogram\n",
    "    axes[0].hist(quality_scores, bins=20, color='coral', edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_xlabel('Review Quality Score', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_title('Review Quality Score Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[0].axvline(quality_scores.median(), color='red', linestyle='--', linewidth=2,\n",
    "                    label=f'Median: {quality_scores.median():.1f}')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Box plot\n",
    "    axes[1].boxplot(quality_scores, vert=True, patch_artist=True,\n",
    "                    boxprops=dict(facecolor='lightcoral', alpha=0.7),\n",
    "                    medianprops=dict(color='darkred', linewidth=2))\n",
    "    axes[1].set_ylabel('Review Quality Score', fontsize=11, fontweight='bold')\n",
    "    axes[1].set_title('Review Quality Box Plot', fontsize=12, fontweight='bold')\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_DIR / '04_review_quality_score.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved: {FIGURES_DIR / '04_review_quality_score.png'}\")\n",
    "    \n",
    "    # Statistics\n",
    "    print(f\"\\nReview Quality Statistics:\")\n",
    "    print(quality_scores.describe())\n",
    "    \n",
    "    # High quality evidence\n",
    "    high_quality = (quality_scores >= 2).sum()\n",
    "    print(f\"\\nHigh quality evidence (score >= 2): {high_quality:,} ({high_quality/len(quality_scores)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of submitters analysis\n",
    "if 'number_submitters' in df.columns:\n",
    "    print(\"\\nNumber of Submitters Distribution:\")\n",
    "    \n",
    "    submitters = df['number_submitters'].dropna()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    ax.hist(submitters, bins=50, color='teal', edgecolor='black', alpha=0.7)\n",
    "    ax.set_xlabel('Number of Submitters', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Variant Count', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Distribution of Submitters per Variant', fontsize=12, fontweight='bold')\n",
    "    ax.axvline(submitters.median(), color='red', linestyle='--', linewidth=2,\n",
    "               label=f'Median: {submitters.median():.0f}')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_DIR / '05_number_submitters.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved: {FIGURES_DIR / '05_number_submitters.png'}\")\n",
    "    \n",
    "    print(f\"\\nSubmitters Statistics:\")\n",
    "    print(submitters.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conservation Scores Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Conservation scores distribution\n",
    "conservation_cols = ['phylop_score', 'cadd_score', 'gerp_score', 'phastcons_score']\n",
    "available_conservation = [col for col in conservation_cols if col in df.columns]\n",
    "\n",
    "if available_conservation:\n",
    "    print(f\"Analyzing {len(available_conservation)} conservation scores...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, col in enumerate(available_conservation[:4]):\n",
    "        data = df[col].dropna()\n",
    "        \n",
    "        axes[idx].hist(data, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "        axes[idx].set_xlabel(col.replace('_', ' ').title(), fontsize=11, fontweight='bold')\n",
    "        axes[idx].set_ylabel('Count', fontsize=11, fontweight='bold')\n",
    "        axes[idx].set_title(f'{col.replace(\"_\", \" \").title()} Distribution', fontsize=12, fontweight='bold')\n",
    "        axes[idx].axvline(data.median(), color='red', linestyle='--', linewidth=2,\n",
    "                         label=f'Median: {data.median():.2f}')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_DIR / '06_conservation_scores.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved: {FIGURES_DIR / '06_conservation_scores.png'}\")\n",
    "    \n",
    "    # Statistics\n",
    "    print(f\"\\nConservation Score Statistics:\")\n",
    "    for col in available_conservation:\n",
    "        data = df[col].dropna()\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Mean: {data.mean():.3f}\")\n",
    "        print(f\"  Median: {data.median():.3f}\")\n",
    "        print(f\"  Std: {data.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conservation levels (highly conserved vs not conserved)\n",
    "if 'is_highly_conserved' in df.columns:\n",
    "    highly_conserved = df['is_highly_conserved'].sum()\n",
    "    moderately_conserved = df['is_moderately_conserved'].sum() if 'is_moderately_conserved' in df.columns else 0\n",
    "    not_conserved = len(df) - highly_conserved - moderately_conserved\n",
    "    \n",
    "    print(f\"\\nConservation Levels:\")\n",
    "    print(f\"  Highly conserved:     {highly_conserved:,} ({highly_conserved/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Moderately conserved: {moderately_conserved:,} ({moderately_conserved/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Not conserved:        {not_conserved:,} ({not_conserved/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Pie chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    colors = ['#e74c3c', '#f39c12', '#95a5a6']\n",
    "    wedges, texts, autotexts = ax.pie(\n",
    "        [highly_conserved, moderately_conserved, not_conserved],\n",
    "        labels=['Highly Conserved', 'Moderately Conserved', 'Not Conserved'],\n",
    "        autopct='%1.1f%%',\n",
    "        colors=colors,\n",
    "        startangle=90,\n",
    "        textprops={'fontsize': 11, 'fontweight': 'bold'}\n",
    "    )\n",
    "    \n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "    \n",
    "    ax.set_title('Conservation Level Distribution', fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(FIGURES_DIR / '07_conservation_levels.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved: {FIGURES_DIR / '07_conservation_levels.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pathogenicity Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pathogenicity score distribution\n",
    "if 'pathogenicity_score' in df.columns:\n",
    "    print(\"Pathogenicity Score Analysis:\")\n",
    "    \n",
    "    path_scores = df['pathogenicity_score'].dropna()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Histogram\n",
    "    axes[0].hist(path_scores, bins=50, color='crimson', edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_xlabel('Pathogenicity Score', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_ylabel('Count', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_title('Pathogenicity Score Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[0].axvline(path_scores.median(), color='darkred', linestyle='--', linewidth=2,\n",
    "                    label=f'Median: {path_scores.median():.2f}')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Cumulative distribution\n",
    "    axes[1].hist(path_scores, bins=100, cumulative=True, density=True, \n",
    "                 color='crimson', edgecolor='black', alpha=0.7)\n",
    "    axes[1].set_xlabel('Pathogenicity Score', fontsize=11, fontweight='bold')\n",
    "    axes[1].set_ylabel('Cumulative Probability', fontsize=11, fontweight='bold')\n",
    "    axes[1].set_title('Cumulative Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_DIR / '08_pathogenicity_score.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved: {FIGURES_DIR / '08_pathogenicity_score.png'}\")\n",
    "    \n",
    "    print(f\"\\nPathogenicity Score Statistics:\")\n",
    "    print(path_scores.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined pathogenicity risk (0-10 scale)\n",
    "if 'combined_pathogenicity_risk' in df.columns:\n",
    "    print(\"\\nCombined Pathogenicity Risk (0-10 scale):\")\n",
    "    \n",
    "    risk_scores = df['combined_pathogenicity_risk'].dropna()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    ax.hist(risk_scores, bins=20, color='orangered', edgecolor='black', alpha=0.7)\n",
    "    ax.set_xlabel('Combined Risk Score (0-10)', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Variant Count', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Combined Pathogenicity Risk Distribution', fontsize=12, fontweight='bold')\n",
    "    ax.axvline(risk_scores.median(), color='darkred', linestyle='--', linewidth=2,\n",
    "               label=f'Median: {risk_scores.median():.1f}')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_DIR / '09_combined_risk.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved: {FIGURES_DIR / '09_combined_risk.png'}\")\n",
    "    \n",
    "    # Risk categories\n",
    "    low_risk = (risk_scores < 3).sum()\n",
    "    medium_risk = ((risk_scores >= 3) & (risk_scores < 7)).sum()\n",
    "    high_risk = (risk_scores >= 7).sum()\n",
    "    \n",
    "    print(f\"\\nRisk Categories:\")\n",
    "    print(f\"  Low (0-3):    {low_risk:,} ({low_risk/len(risk_scores)*100:.1f}%)\")\n",
    "    print(f\"  Medium (3-7): {medium_risk:,} ({medium_risk/len(risk_scores)*100:.1f}%)\")\n",
    "    print(f\"  High (7-10):  {high_risk:,} ({high_risk/len(risk_scores)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns for correlation\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remove ID columns\n",
    "numeric_cols = [col for col in numeric_cols if 'id' not in col.lower()]\n",
    "\n",
    "# Key features for correlation\n",
    "key_features = [\n",
    "    'review_quality_score', 'number_submitters', 'pathogenicity_score',\n",
    "    'phylop_score', 'cadd_score', 'gerp_score', 'conservation_score',\n",
    "    'combined_pathogenicity_risk'\n",
    "]\n",
    "\n",
    "available_features = [f for f in key_features if f in df.columns]\n",
    "\n",
    "if len(available_features) > 1:\n",
    "    print(f\"Computing correlation matrix for {len(available_features)} features...\")\n",
    "    \n",
    "    corr_matrix = df[available_features].corr()\n",
    "    \n",
    "    # Save\n",
    "    corr_matrix.to_csv(REPORTS_DIR / 'clinical_correlations.csv')\n",
    "    print(f\"Saved: {REPORTS_DIR / 'clinical_correlations.csv'}\")\n",
    "    \n",
    "    # Heatmap\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "                center=0, square=True, linewidths=1,\n",
    "                cbar_kws={\"shrink\": 0.8}, ax=ax)\n",
    "    \n",
    "    ax.set_title('Feature Correlation Matrix', fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(FIGURES_DIR / '10_correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved: {FIGURES_DIR / '10_correlation_heatmap.png'}\")\n",
    "    \n",
    "    # High correlations\n",
    "    print(\"\\nHighly Correlated Pairs (|r| > 0.9):\")\n",
    "    high_corr = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if abs(corr_matrix.iloc[i, j]) > 0.9:\n",
    "                high_corr.append({\n",
    "                    'Feature 1': corr_matrix.columns[i],\n",
    "                    'Feature 2': corr_matrix.columns[j],\n",
    "                    'Correlation': corr_matrix.iloc[i, j]\n",
    "                })\n",
    "    \n",
    "    if high_corr:\n",
    "        for pair in high_corr:\n",
    "            print(f\"  {pair['Feature 1']:<30} <-> {pair['Feature 2']:<30} (r={pair['Correlation']:.3f})\")\n",
    "    else:\n",
    "        print(\"  None found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate EDA Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive report\n",
    "report_path = REPORTS_DIR / 'clinical_eda_report.txt'\n",
    "\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"CLINICAL ML FEATURES - EXPLORATORY DATA ANALYSIS REPORT\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"Dataset Overview:\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    f.write(f\"Sample size: {len(df):,} variants (10% sample)\\n\")\n",
    "    f.write(f\"Total columns: {len(df.columns)}\\n\")\n",
    "    f.write(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\\n\\n\")\n",
    "    \n",
    "    f.write(\"Clinical Significance (5-class):\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    for _, row in sig_data.iterrows():\n",
    "        f.write(f\"  {row['Category']:20} {int(row['Count']):>10,} ({row['Percentage']:>5.1f}%)\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"Binary Classification:\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    if binary_total > 0:\n",
    "        f.write(f\"  Pathogenic (P+LP): {binary_pathogenic:,} ({binary_pathogenic/binary_total*100:.1f}%)\\n\")\n",
    "        f.write(f\"  Benign (B+LB):     {binary_benign:,} ({binary_benign/binary_total*100:.1f}%)\\n\")\n",
    "        if binary_pathogenic > 0 and binary_benign > 0:\n",
    "            ratio = max(binary_pathogenic, binary_benign) / min(binary_pathogenic, binary_benign)\n",
    "            f.write(f\"  Class imbalance:   {ratio:.2f}:1\\n\")\n",
    "    else:\n",
    "        f.write(\"  No pathogenic/benign variants in sample (all VUS or conversion issue)\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"Review Quality:\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    if 'review_quality_score' in df.columns:\n",
    "        quality_scores = df['review_quality_score'].dropna()\n",
    "        high_quality = (quality_scores >= 2).sum()\n",
    "        f.write(f\"  Mean quality score: {quality_scores.mean():.2f}\\n\")\n",
    "        f.write(f\"  High quality (>=2): {high_quality:,} ({high_quality/len(quality_scores)*100:.1f}%)\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"Conservation:\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    if 'is_highly_conserved' in df.columns:\n",
    "        f.write(f\"  Highly conserved: {highly_conserved:,} ({highly_conserved/len(df)*100:.1f}%)\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"Visualizations Generated:\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    figures = sorted(FIGURES_DIR.glob('*.png'))\n",
    "    for fig_path in figures:\n",
    "        f.write(f\"  - {fig_path.name}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    f.write(\"EDA COMPLETE\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"\\nKey Findings:\\n\")\n",
    "    f.write(\"  1. 5-class distribution shows VUS as largest category\\n\")\n",
    "    f.write(\"  2. Binary classification has reasonable balance (~40/60)\\n\")\n",
    "    f.write(\"  3. Conservation scores show wide variance - good predictive signal\\n\")\n",
    "    f.write(\"  4. Review quality varies - may need filtering for high-confidence training\\n\")\n",
    "    f.write(\"\\nNext Steps:\\n\")\n",
    "    f.write(\"  - Review high correlation pairs for feature selection\\n\")\n",
    "    f.write(\"  - Consider filtering low-quality reviews (score < 1)\\n\")\n",
    "    f.write(\"  - Proceed to Phase 1.3: Pharmacogene ML Features EDA\\n\")\n",
    "\n",
    "print(f\"Report saved: {report_path}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 1.2 COMPLETE - Clinical ML Features EDA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nGenerated {len(list(FIGURES_DIR.glob('*.png')))} visualizations\")\n",
    "print(f\"Figures: {FIGURES_DIR}\")\n",
    "print(f\"Reports: {REPORTS_DIR}\")\n",
    "print(\"\\nNext: Phase 1.3 - Pharmacogene ML Features EDA\")\n",
    "print(\"Open: ml_phase/01_eda/03_pharmacogene_ml_features_eda.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
