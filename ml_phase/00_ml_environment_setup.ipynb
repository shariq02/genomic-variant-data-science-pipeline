{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 0: ML Environment Setup\n",
    "**DNA Gene Mapping Project - ML Phase**  \n",
    "**Author:** Sharique Mohammad  \n",
    "**Date:** February 2026  \n",
    "**Estimated Time:** 1 hour\n",
    "\n",
    "## Objective\n",
    "Verify local environment, establish PostgreSQL connections, validate data, and set up project structure.\n",
    "\n",
    "## Expected Outcomes\n",
    "- All 11 tables accessible from PostgreSQL\n",
    "- Helper functions created for data loading\n",
    "- Project directories created\n",
    "- Environment validated and documented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Verification (15 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ENVIRONMENT VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"Seaborn version: {sns.__version__}\")\n",
    "print(f\"SQLAlchemy version: {create_engine.__module__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ML libraries\n",
    "try:\n",
    "    import sklearn\n",
    "    print(f\"scikit-learn: {sklearn.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"WARNING: scikit-learn not installed\")\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    print(f\"XGBoost: {xgb.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"WARNING: xgboost not installed\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    print(f\"LightGBM: {lgb.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"WARNING: lightgbm not installed\")\n",
    "\n",
    "print(\"\\nEnvironment check: PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PostgreSQL Connection Test (15 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "load_dotenv()\n",
    "\n",
    "POSTGRES_HOST = os.getenv('POSTGRES_HOST', 'localhost')\n",
    "POSTGRES_PORT = os.getenv('POSTGRES_PORT', '5432')\n",
    "POSTGRES_DB = os.getenv('POSTGRES_DB', 'genome_db')\n",
    "POSTGRES_USER = os.getenv('POSTGRES_USER', 'postgres')\n",
    "POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "\n",
    "if not POSTGRES_PASSWORD:\n",
    "    print(\"ERROR: PostgreSQL password not found in .env file\")\n",
    "else:\n",
    "    print(\"PostgreSQL credentials loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database connection\n",
    "conn_str = f\"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\"\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT 1\"))\n",
    "        print(\"PostgreSQL connection: SUCCESS\")\n",
    "except Exception as e:\n",
    "    print(f\"PostgreSQL connection: FAILED - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify 11 tables exist in gold schema\n",
    "expected_tables = [\n",
    "    'clinical_ml_features',\n",
    "    'disease_ml_features',\n",
    "    'pharmacogene_ml_features',\n",
    "    'structural_variant_ml_features',\n",
    "    'variant_impact_ml_features',\n",
    "    'ml_dataset_variants_train',\n",
    "    'ml_dataset_variants_validation',\n",
    "    'ml_dataset_variants_test',\n",
    "    'ml_dataset_structural_variants_train',\n",
    "    'ml_dataset_structural_variants_validation',\n",
    "    'ml_dataset_structural_variants_test'\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLE VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "missing_tables = []\n",
    "table_info = {}\n",
    "\n",
    "for table_name in expected_tables:\n",
    "    try:\n",
    "        query = f\"SELECT COUNT(*) as count FROM gold.{table_name}\"\n",
    "        result = pd.read_sql(query, engine)\n",
    "        row_count = result['count'].iloc[0]\n",
    "        table_info[table_name] = row_count\n",
    "        print(f\" {table_name:<50} {row_count:>12,} rows\")\n",
    "    except Exception as e:\n",
    "        missing_tables.append(table_name)\n",
    "        print(f\" {table_name:<50} MISSING\")\n",
    "\n",
    "if missing_tables:\n",
    "    print(f\"\\nERROR: {len(missing_tables)} tables missing\")\n",
    "else:\n",
    "    print(f\"\\n SUCCESS: All {len(expected_tables)} tables found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading Utilities (15 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for data loading\n",
    "\n",
    "def load_table_from_postgres(table_name, limit=None, sample_frac=None):\n",
    "    \"\"\"\n",
    "    Load table from PostgreSQL gold schema\n",
    "    \n",
    "    Args:\n",
    "        table_name: Name of table in gold schema\n",
    "        limit: Optional row limit\n",
    "        sample_frac: Optional sampling fraction (0-1)\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame\n",
    "    \"\"\"\n",
    "    query = f\"SELECT * FROM gold.{table_name}\"\n",
    "    \n",
    "    if limit:\n",
    "        query += f\" LIMIT {limit}\"\n",
    "    \n",
    "    df = pd.read_sql(query, engine)\n",
    "    \n",
    "    if sample_frac and 0 < sample_frac < 1:\n",
    "        df = df.sample(frac=sample_frac, random_state=42)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_table_schema(table_name):\n",
    "    \"\"\"\n",
    "    Get column names and types for a table\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    SELECT column_name, data_type \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_schema = 'gold' AND table_name = '{table_name}'\n",
    "    ORDER BY ordinal_position\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query, engine)\n",
    "\n",
    "def get_table_stats(table_name):\n",
    "    \"\"\"\n",
    "    Get basic statistics for a table\n",
    "    \"\"\"\n",
    "    count_query = f\"SELECT COUNT(*) as row_count FROM gold.{table_name}\"\n",
    "    count_df = pd.read_sql(count_query, engine)\n",
    "    \n",
    "    schema_df = get_table_schema(table_name)\n",
    "    \n",
    "    return {\n",
    "        'row_count': count_df['row_count'].iloc[0],\n",
    "        'column_count': len(schema_df),\n",
    "        'columns': schema_df['column_name'].tolist()\n",
    "    }\n",
    "\n",
    "print(\"Helper functions created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test helper functions with sample data\n",
    "print(\"Testing data loading...\\n\")\n",
    "\n",
    "# Load small sample\n",
    "sample_df = load_table_from_postgres('clinical_ml_features', limit=1000)\n",
    "print(f\"Loaded sample: {len(sample_df):,} rows, {len(sample_df.columns)} columns\")\n",
    "print(f\"Memory usage: {sample_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Show first few rows\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "display(sample_df.head(3))\n",
    "\n",
    "# Test schema function\n",
    "schema = get_table_schema('clinical_ml_features')\n",
    "print(f\"\\nSchema: {len(schema)} columns\")\n",
    "print(schema.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Project Structure Setup (15 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "PROJECT_ROOT = Path().absolute().parent\n",
    "\n",
    "output_dirs = [\n",
    "    PROJECT_ROOT / 'data' / 'analytical' / 'figures',\n",
    "    PROJECT_ROOT / 'data' / 'analytical' / 'reports',\n",
    "    PROJECT_ROOT / 'data' / 'ml' / 'metrics',\n",
    "    PROJECT_ROOT / 'models'\n",
    "]\n",
    "\n",
    "for dir_path in output_dirs:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\" {dir_path}\")\n",
    "\n",
    "print(\"\\nProject structure created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# For sklearn (when imported)\n",
    "try:\n",
    "    from sklearn.utils import check_random_state\n",
    "    check_random_state(RANDOM_SEED)\n",
    "    print(f\"Random seed set: {RANDOM_SEED}\")\n",
    "except:\n",
    "    print(f\"NumPy random seed set: {RANDOM_SEED}\")\n",
    "\n",
    "print(\"Reproducibility configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Environment Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate environment status report\n",
    "report_path = PROJECT_ROOT / 'data' / 'analytical' / 'reports' / 'environment_status.txt'\n",
    "\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"ML ENVIRONMENT STATUS REPORT\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"Python Environment:\\n\")\n",
    "    f.write(f\"  Python version: {sys.version}\\n\")\n",
    "    f.write(f\"  Pandas: {pd.__version__}\\n\")\n",
    "    f.write(f\"  NumPy: {np.__version__}\\n\\n\")\n",
    "    \n",
    "    f.write(\"PostgreSQL Connection:\\n\")\n",
    "    f.write(f\"  Host: {POSTGRES_HOST}\\n\")\n",
    "    f.write(f\"  Database: {POSTGRES_DB}\\n\")\n",
    "    f.write(f\"  Status: Connected\\n\\n\")\n",
    "    \n",
    "    f.write(\"Tables Verified (11 total):\\n\")\n",
    "    for table_name, row_count in table_info.items():\n",
    "        f.write(f\"  {table_name}: {row_count:,} rows\\n\")\n",
    "    \n",
    "    f.write(\"\\nProject Directories:\\n\")\n",
    "    for dir_path in output_dirs:\n",
    "        f.write(f\"  {dir_path}\\n\")\n",
    "    \n",
    "    f.write(\"\\nRandom Seed: 42\\n\")\n",
    "    f.write(\"\\nStatus: READY FOR ML PHASE\\n\")\n",
    "\n",
    "print(f\"Environment report saved: {report_path}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 0 COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNext: Phase 1 - Exploratory Data Analysis\")\n",
    "print(\"Open: ml_phase/01_eda/01_disease_ml_features_eda.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
