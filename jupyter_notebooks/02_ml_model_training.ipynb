{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c47d3a-1b8e-4c54-ace8-96883986aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# ML MODEL TRAINING\n",
    "# DNA Gene Mapping Project\n",
    "# Author: Sharique Mohammad\n",
    "# Date: 12 January 2026\n",
    "# ===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526abefb-5974-4bb7-90ba-f62ba6dbba5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a4ddb6-a5e5-4d62-a92b-cceaeb42e672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\Sharique\\Desktop\\Self_Project\\GitHub_Project\\genomic-variant-data-science-pipeline\n",
      "ML directory: C:\\Users\\Sharique\\Desktop\\Self_Project\\GitHub_Project\\genomic-variant-data-science-pipeline\\data\\ml\n",
      "Models directory: C:\\Users\\Sharique\\Desktop\\Self_Project\\GitHub_Project\\genomic-variant-data-science-pipeline\\models\n"
     ]
    }
   ],
   "source": [
    "# Setup Paths\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'jupyter_notebooks' else Path.cwd()\n",
    "ML_DIR = PROJECT_ROOT / \"data\" / \"ml\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "VIZ_DIR = PROJECT_ROOT / \"data\" / \"analytical\" / \"visualizations\"\n",
    "\n",
    "ML_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "VIZ_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"ML directory: {ML_DIR}\")\n",
    "print(f\"Models directory: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cd7e602-e73b-48f4-b9b4-63382bfeac53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ML features from PostgreSQL...\n",
      "Loaded 171 genes with ML features\n"
     ]
    }
   ],
   "source": [
    "# Database Connection & Load Data\n",
    "\n",
    "DB_CONFIG = {\n",
    "    'host': os.getenv('POSTGRES_HOST', 'localhost'),\n",
    "    'port': int(os.getenv('POSTGRES_PORT', 5432)),\n",
    "    'database': os.getenv('POSTGRES_DATABASE', 'genome_db'),\n",
    "    'user': os.getenv('POSTGRES_USER', 'postgres'),\n",
    "    'password': os.getenv('POSTGRES_PASSWORD')\n",
    "}\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}\"\n",
    "    f\"@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    ")\n",
    "\n",
    "print(\"Loading ML features from PostgreSQL...\")\n",
    "df_ml = pd.read_sql(\"SELECT * FROM gold.ml_features\", engine)\n",
    "print(f\"Loaded {len(df_ml)} genes with ML features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad1cb168-ad2c-46ff-a305-414c48d48134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "ML FEATURES OVERVIEW\n",
      "========================================\n",
      "      gene_name chromosome  mutation_count  pathogenic_count  \\\n",
      "0  LOC130067184       None               4                 0   \n",
      "1          EGFR          7             495                 0   \n",
      "2           NF1         17             484                 0   \n",
      "3          CDH1         16             496                 0   \n",
      "4        TATDN2       None               1                 0   \n",
      "\n",
      "   likely_pathogenic_count  total_pathogenic  benign_count  \\\n",
      "0                        0                 0             0   \n",
      "1                        0                 0             0   \n",
      "2                        0                 0             0   \n",
      "3                        0                 0             0   \n",
      "4                        0                 0             0   \n",
      "\n",
      "   likely_benign_count  total_benign  pathogenic_ratio  disease_count  \\\n",
      "0                    0             0                 0              1   \n",
      "1                    0             0                 0              1   \n",
      "2                    0             0                 0              1   \n",
      "3                    0             0                 0              1   \n",
      "4                    0             0                 0              1   \n",
      "\n",
      "   variant_type_count  mutation_density risk_level  \n",
      "0                   1               NaN        Low  \n",
      "1                   1       2569.946680        Low  \n",
      "2                   1       1712.074369        Low  \n",
      "3                   1       5048.602982        Low  \n",
      "4                   1               NaN        Low  \n",
      "\n",
      "Shape: (171, 14)\n",
      "\n",
      "Columns: ['gene_name', 'chromosome', 'mutation_count', 'pathogenic_count', 'likely_pathogenic_count', 'total_pathogenic', 'benign_count', 'likely_benign_count', 'total_benign', 'pathogenic_ratio', 'disease_count', 'variant_type_count', 'mutation_density', 'risk_level']\n",
      "\n",
      "Data types:\n",
      "gene_name                   object\n",
      "chromosome                  object\n",
      "mutation_count               int64\n",
      "pathogenic_count             int64\n",
      "likely_pathogenic_count      int64\n",
      "total_pathogenic             int64\n",
      "benign_count                 int64\n",
      "likely_benign_count          int64\n",
      "total_benign                 int64\n",
      "pathogenic_ratio             int64\n",
      "disease_count                int64\n",
      "variant_type_count           int64\n",
      "mutation_density           float64\n",
      "risk_level                  object\n",
      "dtype: object\n",
      "\n",
      "Target variable distribution:\n",
      "risk_level\n",
      "Low    171\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data Exploration\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"ML FEATURES OVERVIEW\")\n",
    "print(\"=\"*40)\n",
    "print(df_ml.head())\n",
    "print(\"\\nShape:\", df_ml.shape)\n",
    "print(\"\\nColumns:\", df_ml.columns.tolist())\n",
    "print(\"\\nData types:\")\n",
    "print(df_ml.dtypes)\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(df_ml['risk_level'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e34e4d0f-5c1f-4d6d-af7f-786937552811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "FEATURE ENGINEERING\n",
      "========================================\n",
      "Removed 142 genes with NULL chromosome\n",
      "Created additional features:\n",
      "  - benign_ratio\n",
      "  - pathogenic_to_benign\n",
      "  - has_diseases\n",
      "  - high_mutation_density\n",
      "\n",
      "One-hot encoded chromosome (created 13 features)\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering & Preparation\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Remove genes with NULL chromosome\n",
    "df_ml_clean = df_ml[df_ml['chromosome'].notna()].copy()\n",
    "print(f\"Removed {len(df_ml) - len(df_ml_clean)} genes with NULL chromosome\")\n",
    "\n",
    "# Create additional features\n",
    "df_ml_clean['benign_ratio'] = df_ml_clean['total_benign'] / df_ml_clean['mutation_count']\n",
    "df_ml_clean['pathogenic_to_benign'] = df_ml_clean['total_pathogenic'] / (df_ml_clean['total_benign'] + 1)\n",
    "df_ml_clean['has_diseases'] = (df_ml_clean['disease_count'] > 0).astype(int)\n",
    "df_ml_clean['high_mutation_density'] = (df_ml_clean['mutation_density'] > df_ml_clean['mutation_density'].median()).astype(int)\n",
    "\n",
    "print(\"Created additional features:\")\n",
    "print(\"  - benign_ratio\")\n",
    "print(\"  - pathogenic_to_benign\")\n",
    "print(\"  - has_diseases\")\n",
    "print(\"  - high_mutation_density\")\n",
    "\n",
    "# One-hot encode chromosome\n",
    "df_encoded = pd.get_dummies(df_ml_clean, columns=['chromosome'], prefix='chr', drop_first=True)\n",
    "print(f\"\\nOne-hot encoded chromosome (created {len([c for c in df_encoded.columns if c.startswith('chr')])} features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de0a0bd-6042-4f2a-961d-9d157a0db13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "PREPARING FEATURES AND TARGET\n",
      "========================================\n",
      "Features: 28 columns\n",
      "Target: risk_level\n",
      "Samples: 29\n",
      "\n",
      "Feature columns:\n",
      "  1. mutation_count\n",
      "  2. pathogenic_count\n",
      "  3. likely_pathogenic_count\n",
      "  4. total_pathogenic\n",
      "  5. benign_count\n",
      "  6. likely_benign_count\n",
      "  7. total_benign\n",
      "  8. pathogenic_ratio\n",
      "  9. disease_count\n",
      "  10. variant_type_count\n",
      "  ... and 18 more\n",
      "\n",
      "Target distribution:\n",
      "risk_level\n",
      "Low    29\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target proportions:\n",
      "risk_level\n",
      "Low    1.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Prepare Features and Target\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"PREPARING FEATURES AND TARGET\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Define feature columns (exclude target and identifiers)\n",
    "exclude_cols = ['gene_name', 'risk_level', 'created_at']\n",
    "feature_cols = [col for col in df_encoded.columns if col not in exclude_cols]\n",
    "\n",
    "X = df_encoded[feature_cols].copy()\n",
    "y = df_encoded['risk_level'].copy()\n",
    "\n",
    "print(f\"Features: {len(feature_cols)} columns\")\n",
    "print(f\"Target: risk_level\")\n",
    "print(f\"Samples: {len(X)}\")\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print(\"\\nFeature columns:\")\n",
    "for i, col in enumerate(feature_cols[:10], 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "if len(feature_cols) > 10:\n",
    "    print(f\"  ... and {len(feature_cols) - 10} more\")\n",
    "\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(y.value_counts())\n",
    "print(\"\\nTarget proportions:\")\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3acb430-9447-41b8-a504-39d75b5341df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "TRAIN/VAL/TEST SPLIT\n",
      "========================================\n",
      "Encoded classes: ['Low']\n",
      "Train set: 20 samples (69.0%)\n",
      "Val set:   4 samples (13.8%)\n",
      "Test set:  5 samples (17.2%)\n",
      "\n",
      "Train set class distribution:\n",
      "  Low: 20 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: Train/Val/Test Split\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"TRAIN/VAL/TEST SPLIT\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Encode target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "print(f\"Encoded classes: {le.classes_}\")\n",
    "\n",
    "# Split: 70% train, 15% val, 15% test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Train set: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Val set:   {len(X_val)} samples ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set:  {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nTrain set class distribution:\")\n",
    "train_dist = pd.Series(y_train).value_counts()\n",
    "for i, count in train_dist.items():\n",
    "    print(f\"  {le.classes_[i]}: {count} ({count/len(y_train)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8001d786-e9bb-4208-af4e-600023966d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "FEATURE SCALING\n",
      "========================================\n",
      "Applied StandardScaler to all features\n",
      "Feature mean (after scaling): -0.0000\n",
      "Feature std (after scaling): 0.7319\n",
      "\n",
      "Saved scaler to: C:\\Users\\Sharique\\Desktop\\Self_Project\\GitHub_Project\\genomic-variant-data-science-pipeline\\models\\scaler.pkl\n",
      "Saved label encoder to: C:\\Users\\Sharique\\Desktop\\Self_Project\\GitHub_Project\\genomic-variant-data-science-pipeline\\models\\label_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "# CELL 8: Feature Scaling\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"FEATURE SCALING\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Applied StandardScaler to all features\")\n",
    "print(f\"Feature mean (after scaling): {X_train_scaled.mean():.4f}\")\n",
    "print(f\"Feature std (after scaling): {X_train_scaled.std():.4f}\")\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, MODELS_DIR / 'scaler.pkl')\n",
    "joblib.dump(le, MODELS_DIR / 'label_encoder.pkl')\n",
    "print(f\"\\nSaved scaler to: {MODELS_DIR / 'scaler.pkl'}\")\n",
    "print(f\"Saved label encoder to: {MODELS_DIR / 'label_encoder.pkl'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "672edab0-f23a-4c20-b0a4-1226a5d66bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "MODEL 1: LOGISTIC REGRESSION (BASELINE)\n",
      "========================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m40\u001b[39m)\n\u001b[32m      7\u001b[39m lr_model = LogisticRegression(max_iter=\u001b[32m1000\u001b[39m, random_state=\u001b[32m42\u001b[39m, multi_class=\u001b[33m'\u001b[39m\u001b[33mmultinomial\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mlr_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m lr_train_pred = lr_model.predict(X_train_scaled)\n\u001b[32m     11\u001b[39m lr_val_pred = lr_model.predict(X_val_scaled)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1467\u001b[39m     estimator._validate_params()\n\u001b[32m   1469\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1470\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1471\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1472\u001b[39m     )\n\u001b[32m   1473\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1474\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1246\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1244\u001b[39m classes_ = \u001b[38;5;28mself\u001b[39m.classes_\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_classes < \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1246\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1247\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis solver needs samples of at least 2 classes\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1248\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m in the data, but the data contains only one\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1249\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1250\u001b[39m         % classes_[\u001b[32m0\u001b[39m]\n\u001b[32m   1251\u001b[39m     )\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.classes_) == \u001b[32m2\u001b[39m:\n\u001b[32m   1254\u001b[39m     n_classes = \u001b[32m1\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "# Model 1 - Logistic Regression (Baseline)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"MODEL 1: LOGISTIC REGRESSION (BASELINE)\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial')\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "lr_train_pred = lr_model.predict(X_train_scaled)\n",
    "lr_val_pred = lr_model.predict(X_val_scaled)\n",
    "\n",
    "lr_train_acc = accuracy_score(y_train, lr_train_pred)\n",
    "lr_val_acc = accuracy_score(y_val, lr_val_pred)\n",
    "lr_train_f1 = f1_score(y_train, lr_train_pred, average='weighted')\n",
    "lr_val_f1 = f1_score(y_val, lr_val_pred, average='weighted')\n",
    "\n",
    "print(f\"Train Accuracy: {lr_train_acc:.4f}\")\n",
    "print(f\"Train F1-Score: {lr_train_f1:.4f}\")\n",
    "print(f\"Val Accuracy:   {lr_val_acc:.4f}\")\n",
    "print(f\"Val F1-Score:   {lr_val_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Validation):\")\n",
    "print(classification_report(y_val, lr_val_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f09f4-6291-4cef-9342-b7bf9cb78c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 - Random Forest\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"MODEL 2: RANDOM FOREST\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_train_pred = rf_model.predict(X_train)\n",
    "rf_val_pred = rf_model.predict(X_val)\n",
    "\n",
    "rf_train_acc = accuracy_score(y_train, rf_train_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_val_pred)\n",
    "rf_train_f1 = f1_score(y_train, rf_train_pred, average='weighted')\n",
    "rf_val_f1 = f1_score(y_val, rf_val_pred, average='weighted')\n",
    "\n",
    "print(f\"Train Accuracy: {rf_train_acc:.4f}\")\n",
    "print(f\"Train F1-Score: {rf_train_f1:.4f}\")\n",
    "print(f\"Val Accuracy:   {rf_val_acc:.4f}\")\n",
    "print(f\"Val F1-Score:   {rf_val_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Validation):\")\n",
    "print(classification_report(y_val, rf_val_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf1333-d546-4949-8d70-0540d567154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 - XGBoost\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"MODEL 3: XGBOOST\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_train_pred = xgb_model.predict(X_train)\n",
    "xgb_val_pred = xgb_model.predict(X_val)\n",
    "\n",
    "xgb_train_acc = accuracy_score(y_train, xgb_train_pred)\n",
    "xgb_val_acc = accuracy_score(y_val, xgb_val_pred)\n",
    "xgb_train_f1 = f1_score(y_train, xgb_train_pred, average='weighted')\n",
    "xgb_val_f1 = f1_score(y_val, xgb_val_pred, average='weighted')\n",
    "\n",
    "print(f\"Train Accuracy: {xgb_train_acc:.4f}\")\n",
    "print(f\"Train F1-Score: {xgb_train_f1:.4f}\")\n",
    "print(f\"Val Accuracy:   {xgb_val_acc:.4f}\")\n",
    "print(f\"Val F1-Score:   {xgb_val_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Validation):\")\n",
    "print(classification_report(y_val, xgb_val_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36006ea2-4031-4123-ab1e-bf76b136a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 - LightGBM\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"MODEL 4: LIGHTGBM\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "lgbm_model = LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1)\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "lgbm_train_pred = lgbm_model.predict(X_train)\n",
    "lgbm_val_pred = lgbm_model.predict(X_val)\n",
    "\n",
    "lgbm_train_acc = accuracy_score(y_train, lgbm_train_pred)\n",
    "lgbm_val_acc = accuracy_score(y_val, lgbm_val_pred)\n",
    "lgbm_train_f1 = f1_score(y_train, lgbm_train_pred, average='weighted')\n",
    "lgbm_val_f1 = f1_score(y_val, lgbm_val_pred, average='weighted')\n",
    "\n",
    "print(f\"Train Accuracy: {lgbm_train_acc:.4f}\")\n",
    "print(f\"Train F1-Score: {lgbm_train_f1:.4f}\")\n",
    "print(f\"Val Accuracy:   {lgbm_val_acc:.4f}\")\n",
    "print(f\"Val F1-Score:   {lgbm_val_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Validation):\")\n",
    "print(classification_report(y_val, lgbm_val_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff012b-8e0c-497b-964d-a5799dead84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparison\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost', 'LightGBM'],\n",
    "    'Train_Accuracy': [lr_train_acc, rf_train_acc, xgb_train_acc, lgbm_train_acc],\n",
    "    'Val_Accuracy': [lr_val_acc, rf_val_acc, xgb_val_acc, lgbm_val_acc],\n",
    "    'Train_F1': [lr_train_f1, rf_train_f1, xgb_train_f1, lgbm_train_f1],\n",
    "    'Val_F1': [lr_val_f1, rf_val_f1, xgb_val_f1, lgbm_val_f1],\n",
    "    'Overfit_Gap': [\n",
    "        lr_train_f1 - lr_val_f1,\n",
    "        rf_train_f1 - rf_val_f1,\n",
    "        xgb_train_f1 - xgb_val_f1,\n",
    "        lgbm_train_f1 - lgbm_val_f1\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison_df = comparison_df.sort_values('Val_F1', ascending=False)\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "comparison_df.plot(x='Model', y=['Train_Accuracy', 'Val_Accuracy'], \n",
    "                   kind='bar', ax=axes[0], rot=45)\n",
    "axes[0].set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].legend(['Train', 'Validation'])\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# F1-Score comparison\n",
    "comparison_df.plot(x='Model', y=['Train_F1', 'Val_F1'], \n",
    "                   kind='bar', ax=axes[1], rot=45, color=['green', 'orange'])\n",
    "axes[1].set_title('Model F1-Score Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('F1-Score (Weighted)')\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].legend(['Train', 'Validation'])\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(VIZ_DIR / 'model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Select best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_val_f1 = comparison_df.iloc[0]['Val_F1']\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Best Val F1-Score: {best_val_f1:.4f}\")\n",
    "\n",
    "# Map to actual model object\n",
    "model_map = {\n",
    "    'Logistic Regression': lr_model,\n",
    "    'Random Forest': rf_model,\n",
    "    'XGBoost': xgb_model,\n",
    "    'LightGBM': lgbm_model\n",
    "}\n",
    "best_model = model_map[best_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb25a56f-3e43-4dc9-9de4-ee1863a82fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning (Best Model)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"HYPERPARAMETER TUNING: {best_model_name}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "if best_model_name == 'LightGBM':\n",
    "    param_grid = {\n",
    "        'num_leaves': [20, 31, 50],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [5, 7, 10],\n",
    "        'min_child_samples': [10, 20, 30]\n",
    "    }\n",
    "    base_model = LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1)\n",
    "    \n",
    "elif best_model_name == 'Random Forest':\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    base_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    \n",
    "elif best_model_name == 'XGBoost':\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_child_weight': [1, 3, 5]\n",
    "    }\n",
    "    base_model = XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "else:\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1.0, 10.0],\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs', 'saga']\n",
    "    }\n",
    "    base_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial')\n",
    "\n",
    "print(\"Starting RandomizedSearchCV...\")\n",
    "print(f\"Parameter grid: {len(list(param_grid.values())[0]) ** len(param_grid)} combinations\")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    base_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='f1_weighted',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Use scaled data for Logistic Regression, raw for tree-based\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    random_search.fit(X_train_scaled, y_train)\n",
    "else:\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest parameters found:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nBest CV F1-Score: {random_search.best_score_:.4f}\")\n",
    "\n",
    "final_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c84d9-9e64-4071-ab09-150f1d8c7cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model Evaluation\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"FINAL MODEL EVALUATION\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Predictions on all sets\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    final_train_pred = final_model.predict(X_train_scaled)\n",
    "    final_val_pred = final_model.predict(X_val_scaled)\n",
    "    final_test_pred = final_model.predict(X_test_scaled)\n",
    "else:\n",
    "    final_train_pred = final_model.predict(X_train)\n",
    "    final_val_pred = final_model.predict(X_val)\n",
    "    final_test_pred = final_model.predict(X_test)\n",
    "\n",
    "final_train_f1 = f1_score(y_train, final_train_pred, average='weighted')\n",
    "final_val_f1 = f1_score(y_val, final_val_pred, average='weighted')\n",
    "final_test_f1 = f1_score(y_test, final_test_pred, average='weighted')\n",
    "\n",
    "print(f\"Train F1-Score: {final_train_f1:.4f}\")\n",
    "print(f\"Val F1-Score:   {final_val_f1:.4f}\")\n",
    "print(f\"Test F1-Score:  {final_test_f1:.4f}\")\n",
    "\n",
    "print(\"\\nTest Set Classification Report:\")\n",
    "print(classification_report(y_test, final_test_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2808c85-1339-4c9d-ba74-164929058b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Final Model\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"SAVING FINAL MODEL\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(final_model, MODELS_DIR / 'best_model.pkl')\n",
    "print(f\"Saved model to: {MODELS_DIR / 'best_model.pkl'}\")\n",
    "\n",
    "# Save feature names\n",
    "feature_names = {'features': feature_cols}\n",
    "pd.DataFrame([feature_names]).to_json(MODELS_DIR / 'feature_names.json', orient='records')\n",
    "print(f\"Saved feature names to: {MODELS_DIR / 'feature_names.json'}\")\n",
    "\n",
    "# Save model info\n",
    "model_info = {\n",
    "    'model_name': best_model_name,\n",
    "    'train_f1': final_train_f1,\n",
    "    'val_f1': final_val_f1,\n",
    "    'test_f1': final_test_f1,\n",
    "    'best_params': random_search.best_params_,\n",
    "    'n_features': len(feature_cols),\n",
    "    'n_samples': len(X),\n",
    "    'classes': le.classes_.tolist()\n",
    "}\n",
    "\n",
    "pd.DataFrame([model_info]).to_json(MODELS_DIR / 'model_info.json', orient='records', indent=2)\n",
    "print(f\"Saved model info to: {MODELS_DIR / 'model_info.json'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"ML MODEL TRAINING COMPLETE!\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Test F1-Score: {final_test_f1:.4f}\")\n",
    "print(f\"Model saved to: {MODELS_DIR}\")\n",
    "print(\"=\"*40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
